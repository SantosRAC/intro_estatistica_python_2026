---
title: "Dia 04 - Regressão e Correlação"
subtitle: "Introdução à Estatística com Python"
author: "Renato A. Corrêa dos Santos"
date: "2026-02-12"
format:
  revealjs:
    theme: dracula
    transition: fade
    slide-number: true
    show-slide-number: all
    chalkboard: true
    width: 1280
    height: 720
    code-copy: true
    center: true
jupyter: python3
lang: pt-BR
execute:
  echo: true
  warning: false
  error: false
---

# Análises de associação

:::: {.columns}

Podemos calcular associações entre:

 * Variáveis qualitativas

 * Variáveis quantitativas

 * Variáveis qualitativas e quantitativas

::::

## Tabelas de contingência

:::: {.columns}

Tabelas de **dupla entrada** usadas para apresentar dados de **variáveis qualitativas**.

 - Devem apresentar os totais

 - Não devem representar amostras muito pequenas

::::

## Tabelas de contingência com Python

 - **Scipy** é uma das bibliotecas para realização de análises estatísticas

 - Inclui a função `chi2_contingency`


## Tabelas de contingência com Python

:::: {.columns}

Exemplo simples (fumantes/não fumantes, homens/mulheres)

```{python}
import pandas as pd
from scipy.stats import chi2_contingency

fumantes_df = pd.DataFrame({
  "Gender": ["F","M","F","M","F","M","F","M","F","M"],
  "Smokes": ["No","Yes","No","No","Yes","Yes","No","Yes","No","Yes"]
})
```

::::

## Tabelas de contingência com frequências absoluta {.smaller}

:::: {.columns}

```{python}
# tabela de contingência
tab = pd.crosstab(fumantes_df["Gender"], fumantes_df["Smokes"])
print(tab)
```

::::

## Tabelas de contingência com frequências absoluta {.smaller}

:::: {.columns}

```{python}
print(pd.crosstab(fumantes_df["Gender"], fumantes_df["Smokes"], margins=True))
```

::::

## Tabelas de contingência com frequências relativa {.smaller}

:::: {.columns}

```{python}
print(pd.crosstab(fumantes_df["Gender"], fumantes_df["Smokes"], normalize="index"))
```

::::

## Calculando associações entre variáveis qualitativas

:::: {.columns}

Descrever a associação entre as variáveis - conhecer o grau de dependência entre elas.

 - Cálculo de coeficientes de associação ou correlação

 - Valores de Qui-quadrado de Pearson

::::

## Teste de qui-quadrado de Pearson

:::: {.columns}

 - Definição de grupos

 - Definição das hipóteses

 - Definição do nível de significância

 - Cálculo da estatística de teste

Rejeição de hipótese nula em valores de qui-quadrado igual ou maior que o da tabela, para determinado nível de significância e graus de liberdade.

::::

# Teste qui-quadrado de independência

:::: {.columns}

```{python}
chi2, p, dof, expected = chi2_contingency(tab)
print(f"\nQui-quadrado={chi2:.3f}, p-valor={p:.3f}, graus de liberdade={dof}")
print("Contagens esperadas:")
print(pd.DataFrame(expected, index=tab.index, columns=tab.columns))
```

::::

## Tabela referência qui-quadrado

:::: {.columns}

```{python}
from scipy.stats import chi2

alphas = [0.10, 0.05, 0.01]
dofs = [1, 2, 3, 4, 5, 10, 20]

data = {f"α={alpha:.2f}": [chi2.ppf(1 - alpha, df) for df in dofs] for alpha in alphas}
ref_table = pd.DataFrame(data, index=dofs).round(3)
ref_table.index.name = "df"
```

::::

## Tabela referência qui-quadrado

:::: {.columns}

```{python}
print("Tabela Qui-quadrado (valores críticos):")
print(ref_table)
```

::::

## Simulação: caso significativo vs não significativo (Qui-quadrado) {.smaller}

:::: {.columns}

::: {.column}

```{python}
obs_sig = [[30, 5],
       [5, 30]]

obs_nonsig = [[20, 15],
        [18, 17]]
```

:::

::: {.column}

```{python}
def run_chi2(obs, label):
  tab = pd.DataFrame(obs, index=["Grupo 1", "Grupo 2"], columns=["Categoria A", "Categoria B"])
  chi2, p, dof, expected = chi2_contingency(tab)
  print(f"\n== {label} ==")
  print("Tabela observada:")
  print(tab)
  print(f"\nQui-quadrado={chi2:.3f}, p-valor={p:.4f}, df={dof}")
  print("Contagens esperadas:")
  print(pd.DataFrame(expected, index=tab.index, columns=tab.columns))
```

:::

::::

## Simulação: caso significativo vs não significativo (Qui-quadrado) {.smaller}

:::: {.columns}

```{python}
run_chi2(obs_sig, "Associação Significativa (esperado: p < 0.05)")
```

::::

## Simulação: caso significativo vs não significativo (Qui-quadrado) {.smaller}

:::: {.columns}

```{python}
run_chi2(obs_nonsig, "Associação Não Significativa (esperado: p >= 0.05)")
```

::::

## Coeficientes de associação

Há pelo menos dois coeficientes utilizados para **quantificar a associação entre variáveis qualitativas**:

 - Coeficiente fi — φ (phi): usada para variáveis categóricas nominais e varia entre 0 e 1
 - Coeficiente gama — γ (gama): usada para variáveis categóricas ordinais e varia entre -1 e 1

## Quantificando associações

```{python}
from math import sqrt

tables = {
  "Forte": [[45, 5],
            [4, 46]],
  "Moderada": [[30, 20],
               [18, 22]],
  "Fraca": [[20, 17],
            [16, 19]]
}
```

## Quantificando associações

```{python}
def phi_2x2(obs):
  a, b = obs[0]
  c, d = obs[1]
  num = a * d - b * c
  den = sqrt((a + b) * (c + d) * (a + c) * (b + d))
  return num / den
```

## Quantificando associações {.smaller}

```{python}
for label, obs in tables.items():
  tab = pd.DataFrame(obs, index=["Grupo 1", "Grupo 2"], columns=["Cat A", "Cat B"])
  chi2, p, dof, expected = chi2_contingency(tab)
  n = tab.values.sum()
  phi = phi_2x2(obs)
  phi_from_chi2 = (chi2 / n) ** 0.5
  print(f"\n== {label} ==")
  print(tab)
  print(f"chi2={chi2:.3f}, p={p:.4f}, n={n}, phi={phi:.3f}, phi_from_chi2={phi_from_chi2:.3f}")
```

# Análise de correlação

:::: {.columns}

Se **duas variáveis têm valores que tendem a variar conjuntamente**, dizemos que há correlação entre elas.

::::


# Diagrama de dispersão (scatterplot)

:::: {.columns}

Existe correlação quando a nuvem de pontos está disposta na **forma de uma elipse**.

 - A correlação é **positiva** quando X cresce e, em média, Y também cresce;

 - A correlação é **negativa** quando X cresce e, em média, Y decresce;

::::

## Exemplo: Diagrama de Dispersão {.smaller}

:::: {.columns}

::: {.column}

```{python}
#| echo: true
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

np.random.seed(42)
x = np.arange(1, 21)
y = 2 * x + np.random.normal(0, 5, size=x.size)

df = pd.DataFrame({"X": x, "Y": y})
```

:::

::: {.column}

```{python}
plt.figure(figsize=(6,4))
sns.scatterplot(data=df, x="X", y="Y", color="#8be9fd", edgecolor="#444")
sns.regplot(data=df, x="X", y="Y", scatter=False, color="#ff79c6", lowess=True)
plt.title("Correlação Positiva: Diagrama de Dispersão")
plt.tight_layout()
plt.show()
```

:::

::::

# Atenção

No dia a dia, não faz sentido calcular correlação entre X e Y se Y tiver sido criada em função de X.

Os código Python que geram vetores de X e Y são apenas exemplificativos, para visualização e compreensão de conceitos.

# Força da correlação e o diagrama de dispersão

:::: {.columns}

 - Correlação **forte** forma uma elipse fechada em torno de uma reta

 - Correlação **fraca** forma uma elipse arredondada

 - A correlação **nula** é indicada por pontos dispersos

::::

## Correlação fraca

:::: {.columns}

::: {.column}

```{python}
np.random.seed(123)
x_weak = np.linspace(0, 20, 100)
y_weak = 0.3 * x_weak + np.random.normal(0, 5, size=x_weak.size)

df_weak = pd.DataFrame({"X": x_weak, "Y": y_weak})
```

:::

::: {.column}

```{python}
plt.figure(figsize=(6,4))
sns.scatterplot(data=df_weak, x="X", y="Y", color="#8be9fd", edgecolor="#444", alpha=0.8)
sns.regplot(data=df_weak, x="X", y="Y", scatter=False, color="#ff79c6")
plt.title("Correlação Fraca: Diagrama de Dispersão")
plt.tight_layout()
plt.show()
```

:::

::::


# Correlação linear e não linear

:::: {.columns}

 - Correlação **linear**: nuvem de pontos em torno de uma reta

 - Correlação **não linear**: nuvem de pontos em torno de uma curva

::::

## Correlação não linear

:::: {.columns}

::: {.column}

```{python}
np.random.seed(456)
x_parabola = np.linspace(-10, 10, 100)
y_parabola = 0.5 * x_parabola**2 + np.random.normal(0, 5, size=x_parabola.size)

df_parabola = pd.DataFrame({"X": x_parabola, "Y": y_parabola})
```

:::

::: {.column}

```{python}
plt.figure(figsize=(6,4))
sns.scatterplot(data=df_parabola, x="X", y="Y", color="#8be9fd", edgecolor="#444", alpha=0.8)
plt.title("Correlação Não Linear: Diagrama de Dispersão")
plt.xlabel("X")
plt.ylabel("Y")
plt.tight_layout()
plt.show()
```

:::

::::

# Pressupostos para o cálculo de coeficiente de correlação

- Há unidades da amostra para X e para Y

- Unidades foram selecionadas ao acaso e/ou são representativas de uma população

- Variáveis X e Y são independentes


# Cálculo de coeficiente de correlação

Uma das formas de calcular a **correlação linear** entre duas variáveis é através do **coeficiente de correlação de Pearson** (***r***).

- Valor de *r* pode variar entre -1 e 1

- *r* > 0: correlação positiva

- *r* = 0: correlação é nula

- *r* < 0: correlação é negativa

## Calculando coeficiente de correlação Pearson em Python

:::: {.columns}

```{python}
from scipy.stats import pearsonr

x = np.arange(1, 21)
y = 2 * x + np.random.normal(0, 5, size=x.size)

r, p = pearsonr(x, y)

print('Coeficiente de correlação:', r)
print('Valor p:', p)
```

::::

## Calculando coeficiente de correlação Spearman

 - Dados não atendem aos pressupostos para o cálculo de correlação linear (Pearson)

 - Correlação de Spearman é uma medida de associação **monotônica** (relação não muda de direção)

:::: {.columns}

```{python}
from scipy.stats import spearmanr

r, p = spearmanr(x, y)

print('Coeficiente de correlação:', r)
print('Valor p:', p)
```

::::

## Dispersão para correlações com diferentes forças

 - r estima ρ (rho), a correlação populacional

:::: {.columns}

```{python}
np.random.seed(2025)

def simulate_with_corr(n, rho):
  x = np.random.normal(size=n)
  e = np.random.normal(size=n)
  y = rho * x + np.sqrt(1 - rho**2) * e
  return pd.DataFrame({"X": x, "Y": y})

rhos = [0.25, 0.50, 0.75, 0.99]
dfs = {rho: simulate_with_corr(500, rho) for rho in rhos}
corrs = {rho: dfs[rho]["X"].corr(dfs[rho]["Y"]) for rho in rhos}
```

::::

## Dispersão para correlações com diferentes forças {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
fig, axes = plt.subplots(2, 2, figsize=(7, 4))
axes = axes.flatten()
for ax, rho in zip(axes, rhos):
  sns.scatterplot(data=dfs[rho], x="X", y="Y", color="#8be9fd", edgecolor="#444", alpha=0.8, ax=ax)
  sns.regplot(data=dfs[rho], x="X", y="Y", scatter=False, color="#ff79c6", ax=ax)
  ax.set_title(f"Alvo r={rho:.2f} | Pearson≈{corrs[rho]:.2f}")
plt.tight_layout()
plt.show()
```

::::

# Análises de associação e correlação com o dataset dos pinguins {.smaller}

## Dataset pinguins {.smaller}

:::: {.columns}

::: {.column}


```{python}
from palmerpenguins import load_penguins
penguins = load_penguins()
penguins.head()
```

:::

::: {.column}

```{python}
print("Número de variáveis:\n", penguins.columns)
print("Dimensões do dataframe:\n", penguins.shape)
print("Tipo de dados:\n", penguins.dtypes)
```

:::

::::

## Dataset pinguins {.smaller}

:::: {.columns}

```{python}
print("\nNulos por coluna:")
print(penguins.isna().sum())
```

::::

## Dataset pinguins - variáveis categóricas {.smaller}

:::: {.columns}

::: {.column}

```{python}
counts = {col: penguins[col].value_counts(dropna=False) for col in ['species', 'island', 'sex']}

print("Counts (including NaN):")
for col, ser in counts.items():
  print(f"\n{col}:\n{ser.to_string()}")
```

:::

::: {.column}

```{python}
tab_counts = penguins.fillna({'sex': 'missing'}).groupby(['species', 'sex', 'island']).size().unstack(level='island', fill_value=0)
print("Counts of species × sex × island:")
print(tab_counts)
```

:::

::::

## Dataset pinguins - coletas ao longo de três anos {.smaller}

:::: {.columns}

```{python}
# counts by year and species
counts = (
  penguins.dropna(subset=['year','species'])
  .groupby(['year','species'])
  .size()
  .reset_index(name='count')
)

pivot = counts.pivot(index='year', columns='species', values='count').fillna(0)

pivot.head()
```

::::

## Dataset pinguins - coletas ao longo de três anos {.smaller}

:::: {.columns}

 - Usando a função de dataframe `.plot()` ("stacked" ou "empilhado"):

```{python}
#| fig-align: center
pivot.plot(kind='bar', stacked=True, colormap='tab20', legend=True,
          xlabel='Year', ylabel='Species', title='Species collected by year', figsize=(8,4))
```

::::

## Dataset pinguins - coletas ao longo de três anos {.smaller}

:::: {.columns}

 - Usando Matplotlib:

```{python}
#| fig-align: center
plt.figure(figsize=(6,3))
sns.barplot(data=counts, x='year', y='count', hue='species')
plt.title('Species collected by year (grouped)')
plt.xlabel('Year')
plt.ylabel('Count')
plt.tight_layout()
plt.show()
```

::::

## Dataset pinguins - variáveis numéricas

:::: {.columns}

 - Resumo numérico das colunas numéricas com float:

```{python}
penguins_float_data = penguins.select_dtypes(include='float64')
print("Resumo numérico (apenas float64):")
print(penguins_float_data.describe().round(3))
```

::::

## Dataset pinguins - resumindo estatísticas dos pinguins

:::: {.columns}

 - Recuperando estatísticas para cada característica de pinguins:

```{python}
print("\nEstatísticas (média e desvio padrão) por espécie:")
summary_species_traits = penguins[['species', 'bill_length_mm', 'bill_depth_mm',
       'flipper_length_mm', 'body_mass_g']].groupby('species')[['bill_length_mm', 'bill_depth_mm',
       'flipper_length_mm', 'body_mass_g']].describe().round(3)
print(summary_species_traits.head())
```

::::

## Dataset pinguins - resumindo estatísticas dos pinguins

:::: {.columns}

```{python}
print("Estatísticas de comprimento da nadadeira (mm) por espécie")
print(summary_species_traits['flipper_length_mm'])
print("Apenas médias de comprimento da nadadeira")
print(summary_species_traits[('flipper_length_mm', 'mean')])
```

::::

## Dataset pinguins - estatísticas de nadadeira {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
plt.figure(figsize=(8,4))
sns.kdeplot(
  data=penguins.dropna(subset=['flipper_length_mm','species']),
  x='flipper_length_mm', hue='species', fill=True, common_norm=False,
  alpha=0.6
)
plt.title('Distribuição de comprimento da nadadeira por espécie')
plt.xlabel('Comprimento da nadadeira (mm)')
plt.tight_layout()
plt.show()
```

::::

## Dataset pinguins - Comprimento dos bicos {.smaller}

 - O caderno ["Brief Analysis of Adelie Penguins"](https://rpubs.com/CJTA/948742) de Christopher Taylor tem uma imagem mostrando depth e length.

:::: {.columns}

```{python}
#| fig-align: center
plt.figure(figsize=(6,3))
sns.kdeplot(
  data=penguins.dropna(subset=['bill_length_mm','species']),
  x='bill_length_mm', hue='species', fill=True, common_norm=False,
  alpha=0.6
)
plt.title('Distribuição de comprimento do bico por espécie')
plt.xlabel('Comprimento do bico (mm)')
plt.tight_layout()
plt.show()
```

::::

## Dataset pinguins - Profundidade dos bicos {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
plt.figure(figsize=(8,4))
sns.kdeplot(
  data=penguins.dropna(subset=['bill_depth_mm','species']),
  x='bill_depth_mm', hue='species', fill=True, common_norm=False,
  alpha=0.6
)
plt.title('Distribuição de profundidade do bico por espécie')
plt.xlabel('Profundidade do bico (mm)')
plt.tight_layout()
plt.show()
```

::::

## Dataset pinguins - estatísticas de massa corporal {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
plt.figure(figsize=(8,4))
sns.kdeplot(
  data=penguins.dropna(subset=['body_mass_g','species']),
  x='body_mass_g', hue='species', fill=True, common_norm=False,
  alpha=0.6
)
plt.title('Distribuição de massa corporal por espécie')
plt.xlabel('Massa corporal (g)')
plt.tight_layout()
plt.show()
```

::::

## Perguntas

 - As proporções de sexo coletadas para as espécies se mantêm ao longo dos anos?

 - Existe **associação** entre ilha e certas características dos pinguins? (Adelie é a única espécie distribuída nas três ilhas)

 - Há **associação** entre sexo e as ilha? (Adelie é a única espécie distribuída nas três ilhas)

 - Existe **associação** entre tamanho de bico e espécie?


## Tabelas de contingência - espécies e ilhas

:::: {.columns}

 - Apenas Adelie é observada nas três ilhas.

 - Não vale a pena testar casos óbvios, respondidos na análise exploratória. ??

```{python}
tab_contingencia = pd.crosstab(penguins['island'], penguins['species'])
print('Tabela de contingência:')
print(tab_contingencia)
```

::::

## Tabelas de contingência - ilhas e sexo (Adelie)

:::: {.columns}

 - Tabela de contingência **ilhas vs. sexo**

 - Como foi feita a coleta? Amostragem aleatória?

```{python}
pd.crosstab(penguins[penguins['species']=='Adelie']['island'], penguins[penguins['species']=='Adelie']['sex'])
```

::::

## Tabelas de contingência - ilhas e sexo (Adelie)

:::: {.columns}

```{python}
adelie_df = penguins.query("species == 'Adelie'").copy()
adelie_df.reset_index(drop=True, inplace=True)
adelie_tab_freq = pd.crosstab(adelie_df['island'], adelie_df['sex'])
print('Tabela de contingência:')
print(adelie_tab_freq)
```

::::

## Teste Qui-quadrado de Pearson - ilhas e sexo (Adelie) {.smaller}

:::: {.columns}

```{python}
chi2_c, p_c, dof_c, expected_c = chi2_contingency(adelie_tab_freq)
print("Contingency table (island × sex):")
print(adelie_tab_freq)
print(f"\nChi-square test of independence -> chi2={chi2_c:.3f}, p={p_c:.4f}, df={dof_c}")
print("Expected counts:")
print(pd.DataFrame(expected_c, index=adelie_tab_freq.index, columns=adelie_tab_freq.columns))
```

::::

## Teste Qui-quadrado de Pearson - ilhas e sexo (Adelie) {.smaller}

 * Importação de `chi2` (do `scipy`) pela segunda vez (atribuição de valor a chi2 após importação do scipy)

:::: {.columns}

```{python}
from scipy.stats import chi2

alpha = 0.05
chi2_crit = chi2.ppf(1 - alpha, dof_c)

print(f"Chi2 estatística = {chi2_c:.3f}, p-valor = {p_c:.4f}, df = {dof_c}, α = {alpha}")
print(f"Valor crítico χ²(1-α, df) = {chi2_crit:.3f}")

if p_c < alpha or chi2_c >= chi2_crit:
  print("Resultado significativo: rejeita H0 -> há evidência de associação entre ilha e sexo (Adelie).")
else:
  print("Resultado não significativo: falha em rejeitar H0 -> sem evidência de associação entre ilha e sexo (Adelie).")
```

::::

## Tabelas de contingência (freq. relativa) - ilhas e sexo (Adelie)

:::: {.columns}

```{python}
adelie_tab_freq_relativa = pd.crosstab(adelie_df['island'], adelie_df['sex'], normalize='all')
print('Tabela de contingência:')
print(adelie_tab_freq_relativa)
```

::::

## Calculando frequencias relativas pinguins


```{python}
from scipy.stats import chisquare

# islands observed for Adelie
islands = sorted(adelie_df['island'].dropna().unique())

# 1) Goodness-of-fit: are counts equal across the three islands?
obs_all = adelie_df['island'].value_counts().reindex(islands, fill_value=0).values
exp_all = np.full_like(obs_all, obs_all.sum() / obs_all.size, dtype=float)
chi2_all, p_all = chisquare(f_obs=obs_all, f_exp=exp_all)
print("All Adelie (counts by island):", dict(zip(islands, obs_all)))
print(f"Goodness-of-fit -> chi2={chi2_all:.3f}, p={p_all:.4f}, df={len(obs_all)-1}\n")

# 2) Same test separately for each sex
for sex in adelie_df['sex'].dropna().unique():
  obs_sex = adelie_df[adelie_df['sex'] == sex]['island'].value_counts().reindex(islands, fill_value=0).values
  if obs_sex.sum() == 0:
    continue
  exp_sex = np.full_like(obs_sex, obs_sex.sum() / obs_sex.size, dtype=float)
  chi2_s, p_s = chisquare(f_obs=obs_sex, f_exp=exp_sex)
  print(f"Sex={sex}: counts={dict(zip(islands, obs_sex))}")
  print(f"  Goodness-of-fit -> chi2={chi2_s:.3f}, p={p_s:.4f}, df={len(obs_sex)-1}\n")

# 3) Contingency test (island vs sex) as alternative (tests independence)
tab = pd.crosstab(adelie_df['island'], adelie_df['sex'])
chi2_c, p_c, dof_c, expected_c = chi2_contingency(tab)
print("Contingency table (island × sex):")
print(tab)
print(f"\nChi-square test of independence -> chi2={chi2_c:.3f}, p={p_c:.4f}, df={dof_c}")
print("Expected counts:")
print(pd.DataFrame(expected_c, index=tab.index, columns=tab.columns))
```

## Análises de correlação - Perguntas

 - Existe **correlação** entre tamanho e/ou profundidade do bico, comprimento da nadadeira e massa corporal em uma ou mais espécies?

 - As **correlações** são significativas independente do sexo do pinguim?

## Análises de correlação

:::: {.columns}

```{python}
penguins_float_data = penguins[["bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g", "species", "sex"]]
print(penguins_float_data.head())
```

::::

## Análises de correlação

:::: {.columns}

 - Atenção para os dados faltantes

```{python}
print(penguins_float_data["bill_length_mm"])
```

::::

## Análises de correlação - dados faltantes

:::: {.columns}

```{python}
na_species = penguins_float_data['species'].isna().sum()
na_sex = penguins_float_data['sex'].isna().sum()
print(f"NAs em species: {na_species}")
print(f"NAs em sex: {na_sex}")
```

::::

## Análises de correlação - dados faltantes

 - Remoção: número de observações para cada espécie / sexo muda

 - Dataset dos pinguins: NaN aparece em todas as colunas para um indivíduo, para as variáveis numéricas

:::: {.columns}

```{python}
rows_with_nan = penguins_float_data[penguins_float_data.isna().any(axis=1)]
print(f"Linhas com NaN em pelo menos uma coluna: {rows_with_nan.shape[0]}")
print(rows_with_nan)
print(penguins_float_data.loc[[3, 271]])
```

::::

## Análises de correlação - dados faltantes

 - Removendo linhas com índices 3 e 271 (todas as variáveis numéricas ausentes)

 - Poderíamos remover outras linhas (por exemplo, sem informação de sexo)

:::: {.columns}

```{python}
print(penguins_float_data.shape)
penguins_float_data = penguins_float_data.drop(index=[3, 271])
print(penguins_float_data.shape)
```

::::

## Análise exploratória dos dados - algumas perguntas

- As variáveis parecem se relacionar linearmente?

  - Comprimento e profundidade do bico
  - Comprimento do bico e da nadadeira
  - Comprimento do bico e massa corporal

## Análise exploratória dos dados {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
df_plot = penguins_float_data.dropna(subset=['bill_length_mm', 'bill_depth_mm'])
plt.figure(figsize=(6,4))
sns.scatterplot(
  data=df_plot, x='bill_length_mm',
  y='bill_depth_mm', color='#8be9fd',
  edgecolor='#444', alpha=0.85
)
plt.xlabel('Comprimento do bico (mm)')
plt.ylabel('Profundidade do bico (mm)')
plt.title('Comprimento vs. Profundidade do bico')
plt.tight_layout()
plt.show()
```

::::

## Análise exploratória dos dados - algumas perguntas adicionais

As variáveis parecem se relacionar linearmente

- Por espécie?
- Por sexo?

## Análise exploratória dos dados {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
df_plot = penguins_float_data.dropna(subset=['bill_length_mm', 'bill_depth_mm', 'species']).copy()
order = ['Adelie', 'Chinstrap', 'Gentoo']
df_plot['species'] = pd.Categorical(df_plot['species'], categories=order, ordered=True)

g = sns.FacetGrid(
  df_plot, col='species', col_order=order,
  sharex=True, sharey=True, height=3, aspect=1
)
g.map_dataframe(
  sns.scatterplot, x='bill_length_mm', y='bill_depth_mm',
  color='#8be9fd', edgecolor='#444', alpha=0.85
)
g.set_axis_labels('Comprimento do bico (mm)', 'Profundidade do bico (mm)')
g.set_titles('{col_name}')
plt.tight_layout()
plt.show()
```

::::

## Análise exploratória dos dados {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
df_plot_species = penguins_float_data.dropna(subset=['bill_length_mm', 'bill_depth_mm', 'species']).copy()
order = ['Adelie', 'Chinstrap', 'Gentoo']
df_plot_species['species'] = pd.Categorical(df_plot_species['species'], categories=order, ordered=True)
plt.figure(figsize=(6,4))
sns.scatterplot(data=df_plot_species, x='bill_length_mm', y='bill_depth_mm',
  hue='species', hue_order=order, palette='Set2', edgecolor='#444', alpha=0.85)
plt.xlabel('Comprimento do bico (mm)')
plt.ylabel('Profundidade do bico (mm)')
plt.title('Comprimento vs. Profundidade do bico por espécie')
plt.legend(title='Espécie')
plt.tight_layout()
plt.show()
```

::::

## Análises de correlação - Pearson {.smaller}

 - Comprimento e profundidade do bico

:::: {.columns}

```{python}
# "bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g"
r_p, p_p = pearsonr(penguins_float_data["bill_length_mm"], penguins_float_data["bill_depth_mm"])
print(f"Pearson (Todas as espécies): r={r_p:.3f}, p={p_p:.4g}")

r_p, p_p = pearsonr(penguins_float_data[penguins_float_data["species"]=="Adelie"]["bill_length_mm"],
  penguins_float_data[penguins_float_data["species"]=="Adelie"]["bill_depth_mm"])
print(f"Pearson (Adelie): r={r_p:.3f}, p={p_p:.4g}")

r_p, p_p = pearsonr(penguins_float_data[penguins_float_data["species"]=="Chinstrap"]["bill_length_mm"],
  penguins_float_data[penguins_float_data["species"]=="Chinstrap"]["bill_depth_mm"])
print(f"Pearson (Chinstrap): r={r_p:.3f}, p={p_p:.4g}")

r_p, p_p = pearsonr(penguins_float_data[penguins_float_data["species"]=="Gentoo"]["bill_length_mm"],
  penguins_float_data[penguins_float_data["species"]=="Gentoo"]["bill_depth_mm"])
print(f"Pearson (Gentoo): r={r_p:.3f}, p={p_p:.4g}")
```

::::

## Gráficos Chinstrap {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
df_chinstrap = penguins_float_data.dropna(subset=['bill_length_mm', 'bill_depth_mm', 'species'])
df_chinstrap = df_chinstrap[df_chinstrap['species'] == 'Chinstrap']
b, a = np.polyfit(df_chinstrap['bill_length_mm'], df_chinstrap['bill_depth_mm'], 1)
x_line = np.linspace(df_chinstrap['bill_length_mm'].min(), df_chinstrap['bill_length_mm'].max(), 200)
plt.figure(figsize=(6,3))
sns.scatterplot(data=df_chinstrap, x='bill_length_mm', y='bill_depth_mm', color='#8be9fd', edgecolor='#444', alpha=0.85)
plt.plot(x_line, a + b * x_line, color='#ff79c6', linewidth=2, label=f'y = {a:.2f} + {b:.2f}x')
plt.title('Chinstrap: Comprimento vs. Profundidade do bico')
plt.xlabel('Comprimento do bico (mm)'); plt.ylabel('Profundidade do bico (mm)')
plt.legend(); plt.tight_layout(); plt.show()
```

::::

## Gráficos Gentoo {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
df_gentoo = penguins_float_data.dropna(subset=['bill_length_mm', 'bill_depth_mm', 'species'])
df_gentoo = df_gentoo[df_gentoo['species'] == 'Gentoo']
b, a = np.polyfit(df_gentoo['bill_length_mm'], df_gentoo['bill_depth_mm'], 1)
x_line = np.linspace(df_gentoo['bill_length_mm'].min(), df_gentoo['bill_length_mm'].max(), 200)
plt.figure(figsize=(6,3))
sns.scatterplot(data=df_gentoo, x='bill_length_mm', y='bill_depth_mm', color='#8be9fd', edgecolor='#444', alpha=0.85)
plt.plot(x_line, a + b * x_line, color='#ff79c6', linewidth=2, label=f'y = {a:.2f} + {b:.2f}x')
plt.title('Gentoo: Comprimento vs. Profundidade do bico')
plt.xlabel('Comprimento do bico (mm)'); plt.ylabel('Profundidade do bico (mm)')
plt.legend(); plt.tight_layout(); plt.show()
```

::::

## Correlação na espécie Adelie {.smaller}

 - Parece que a correlação entre comprimento e profundidade do bico é menor que para as demais espécies

 - Adelie é a única distribuída nas três ilhas: será que há alguma diferença entre elas?

## Inspecionando uma única espécie (Adelie)

:::: {.columns}

```{python}
#| fig-align: center
df_adelie = penguins_float_data.dropna(subset=['bill_length_mm', 'bill_depth_mm', 'species'])
df_adelie = df_adelie[df_adelie['species'] == 'Adelie']
b, a = np.polyfit(df_adelie['bill_length_mm'], df_adelie['bill_depth_mm'], 1)
x_line = np.linspace(df_adelie['bill_length_mm'].min(), df_adelie['bill_length_mm'].max(), 200)
plt.figure(figsize=(6,3))
sns.scatterplot(data=df_adelie, x='bill_length_mm', y='bill_depth_mm', color='#8be9fd', edgecolor='#444', alpha=0.85)
plt.plot(x_line, a + b * x_line, color='#ff79c6', linewidth=2, label=f'y = {a:.2f} + {b:.2f}x')
plt.title('Adelie: Comprimento vs. Profundidade do bico')
plt.xlabel('Comprimento do bico (mm)'); plt.ylabel('Profundidade do bico (mm)')
plt.legend(); plt.tight_layout(); plt.show()
```

::::


## Análises de correlação - Pearson

:::: {.columns}

::: {.column}

- Comprimento do bico e da nadadeira

```{python}
r_p, p_p = pearsonr(penguins_float_data["bill_length_mm"], penguins_float_data["flipper_length_mm"])
print(f"Pearson: r={r_p:.3f}, p={p_p:.4g}")
```

:::

::: {.column}

- Comprimento do bico e massa corporal

```{python}
r_p, p_p = pearsonr(penguins_float_data["bill_length_mm"], penguins_float_data["body_mass_g"])
print(f"Pearson: r={r_p:.3f}, p={p_p:.4g}")
```

:::

::::

## Análises de correlação - Spearman

:::: {.columns}

```{python}
# "bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g"
r_s, p_s = spearmanr(penguins_float_data["bill_length_mm"], penguins_float_data["bill_depth_mm"])
print(f"Spearman: rho={r_s:.3f}, p={p_s:.4g}")
```

::::

# Análise de regressão

:::: {.columns}

A análise de regressão permite examinar o efeito de uma **variável explicativa** (ou mais de uma) sobre uma **variável resposta**.

 - Vamos analisar **regressão linear** entre *duas variáveis*

::::

## Equação da reta

:::: {.columns}

Equação da reta (modelo linear simples):

$$
Y_i = a + b\,X_i
$$

- α (alpha) é o intercepto (termo constante)
- β (beta) é o coeficiente angular (inclinação)

::::

# Valores de coeficientes

:::: {.columns}

Diferentes valores de coeficiente angular:

```{python}
#| echo: true
rng = np.random.default_rng(2025)
n = 60
x = rng.uniform(0, 10, size=n)

slopes = [(-1.8, "Negativa"), (0.0, "Nula"), (1.5, "Positiva")]
intercept = 2.0
noise_scale = 1.8
```

::::

## Valores de coeficientes lineares (intercepto) {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
intercepts = [-3.0, 0.0, 4.5]
slope = 1.2
noise_scale = 1.8

fig, axes = plt.subplots(1, len(intercepts), figsize=(10, 3))
x_line = np.linspace(x.min(), x.max(), 200)

for ax, a in zip(axes, intercepts):
  y = a + slope * x + rng.normal(0, noise_scale, size=n)
  ax.scatter(x, y, c="#8be9fd", edgecolors="#444", alpha=0.85)
  ax.plot(x_line, a + slope * x_line, color="#ff79c6", linewidth=2)
  ax.set_title(f"Intercepto a={a:+.1f} | Inclinação b={slope:+.2f}")
  ax.set_xlabel("X")
  ax.set_ylabel("Y")
  ax.grid(alpha=0.25)

plt.tight_layout()
plt.show()
```

::::

## Valores de coeficientes angulares {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
fig, axes = plt.subplots(1, 3, figsize=(11, 3.5))
x_line = np.linspace(x.min(), x.max(), 200)

for ax, (b, label) in zip(axes, slopes):
  y = intercept + b * x + rng.normal(0, noise_scale, size=n)
  ax.scatter(x, y, c="#8be9fd", edgecolors="#444", alpha=0.85)
  ax.plot(x_line, intercept + b * x_line, color="#ff79c6", linewidth=2)
  ax.set_title(f"Inclinação {label}: b={b:+.2f}")
  ax.set_xlabel("X")
  ax.set_ylabel("Y")
  ax.grid(alpha=0.25)

plt.tight_layout()
plt.show()
```

::::

# Regressão linear simples

Vamos **ajustar uma regressão linear simples** a um conjunto de dados.

 - Linear: reta
 - Simples: apenas uma variável explicativa

## Obtenção do coeficiente angular

:::: {.columns}

$$
b = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}
$$

::::

## Obtenção do coeficiente linear (intercepto)

:::: {.columns}

$$
a = \bar{y} - b\,\bar{x}
$$

::::

## Pontos criados a partir dos coeficientes {.smaller}

:::: {.columns}

::: {.column}

```{python}
#| echo: true
a_coef = 2.16
b_coef = -0.985
rng_sim = np.random.default_rng(2027)
x_sim = rng_sim.uniform(-15, 15, size=40)
y_sim = a_coef + b_coef * x_sim + rng_sim.normal(0, 1.0, size=x_sim.size)
df_sim = pd.DataFrame({"X": x_sim, "Y": y_sim}).sort_values("X").reset_index(drop=True)
```

:::

::: {.column}

```{python}
df_sim.head(10)
```

:::

::::

## Pontos criados a partir dos coeficientes {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
plt.figure(figsize=(6,4))
sns.scatterplot(data=df_sim, x="X", y="Y", color="#8be9fd", edgecolor="#444", alpha=0.85)
plt.title("Pontos simulados (df_sim)")
plt.xlabel("X")
plt.ylabel("Y")
plt.tight_layout()
plt.show()
```

::::

## Condições para ajuste da regressão linear simples

- Variáveis devem ser **contínuas**

- Relação entre elas deve ser **linear**

- Observações devem ser **independentes**

Não trataremos de casos envolvendo variáveis discretas (embora esta análise de regressão seja possível)

## Escolha de variáveis explicativas

:::: {.columns}


::::

## Extrapolação

:::: {.columns}


::::

# Análises de regressão linear com o dataset dos pinguins {.smaller}

## Dataset pinguins {.smaller}

:::: {.columns}

```{python}
from palmerpenguins import load_penguins
penguins = load_penguins()
penguins.head()
```

::::

## Objetivos das análises com o dataset dos pinguins

:::: {.columns}

 - Construir um modelo de regressão linear

 - Avaliar a qualidade do modelo

 - Verificar se as premissas da análise são cumpridas

 - Fazer predições

::::

## Dataset pinguins {.smaller}

:::: {.columns}

```{python}
penguins_subset = penguins[['species', 'bill_length_mm', 'bill_depth_mm',
       'flipper_length_mm', 'body_mass_g']]
penguins_subset.head()
```

::::

## Dados faltantes no dataset de pinguins {.smaller}

:::: {.columns}

 - Não é possível fazer a análise com dados faltantes! (sim, o dia a dia é cheio de exceções rs veremos isso novamente amanhã)

```{python}
print("Dimensões do dataframe depois:\n", penguins_subset.shape)
na_counts = penguins_subset.isna().sum()
print("Dados faltantes por coluna:\n", na_counts)
penguins_subset = penguins_subset.dropna(subset=["bill_length_mm"])
print("Dimensões do dataframe depois:\n", penguins_subset.shape)
```

::::

## Dataset pinguins - dados bico {.smaller}

:::: {.columns}

```{python}
#| fig-align: center
df_plot = penguins_subset.dropna(subset=['bill_depth_mm', 'bill_length_mm'])
plt.figure(figsize=(6,4))
sns.scatterplot(data=df_plot, x='bill_depth_mm', y='bill_length_mm',
        color='#8be9fd', edgecolor='#444', alpha=0.85)
plt.xlabel('Profundadide do bico (mm)')
plt.ylabel('Comprimento do bico (mm)')
plt.title('Profundidade vs. Comprimento bico')
plt.tight_layout()
plt.show()
```

::::

## Dataset pinguins - bico ou nadadeira vs. massa corporal {.smaller}

:::: {.columns}

::: {.column}

```{python}
#| fig-align: center
df_plot = penguins_subset.dropna(subset=['body_mass_g', 'bill_depth_mm'])
plt.figure(figsize=(6,4))
sns.scatterplot(data=df_plot, x='body_mass_g', y='bill_depth_mm',
        color='#8be9fd', edgecolor='#444', alpha=0.85)
plt.xlabel('Massa corporal (g)')
plt.ylabel('Profundidade do bico (mm)')
plt.title('Massa corporal vs. Profundidade bico')
plt.tight_layout()
plt.show()
```

:::

::: {.column}

```{python}
#| fig-align: center
df_plot = penguins_subset.dropna(subset=['body_mass_g', 'bill_length_mm'])
plt.figure(figsize=(6,4))
sns.scatterplot(data=df_plot, x='body_mass_g', y='bill_length_mm',
        color='#8be9fd', edgecolor='#444', alpha=0.85)
plt.xlabel('Massa corporal (g)')
plt.ylabel('Comprimento do bico (mm)')
plt.title('Massa corporal vs. Comprimento bico')
plt.tight_layout()
plt.show()
```

:::

::::

## Criando o modelo linear {.smaller}

:::: {.columns}

```{python}
from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(penguins_subset[['body_mass_g']],
  penguins_subset[['bill_depth_mm']])
print(lin_reg.intercept_, lin_reg.coef_)
```

::::

## Avaliando o modelo linear {.smaller}

:::: {.columns}

```{python}
import statsmodels.api as sm
from statsmodels.stats.diagnostic import het_breuschpagan

# ensure same rows used for fitting
df_model = penguins_subset.dropna(subset=['body_mass_g', 'bill_depth_mm']).copy()
X = df_model[['body_mass_g']].values
y = df_model['bill_depth_mm'].values

# predictions and residuals
y_pred = lin_reg.predict(X).ravel()
resid = y - y_pred
```

::::

## Avaliando o modelo linear - Normalidade dos resíduos {.smaller}

:::: {.columns}

```{python}
plt.figure(figsize=(6,4))
sns.histplot(resid, kde=True, color="#8be9fd", edgecolor="#444", stat="density")
plt.axvline(np.mean(resid), color="#ff79c6", linestyle="--", linewidth=1.5, label=f"mean={resid.mean():.3f}")
plt.xlabel("Residuals")
plt.ylabel("Density")
plt.title("Histogram of Residuals")
plt.legend()
plt.tight_layout()
plt.show()
```

::::

## Avaliando o modelo linear {.smaller}

:::: {.columns}

```{python}
# Residuals vs Fitted
plt.figure(figsize=(6,4))
sns.scatterplot(x=y_pred, y=resid, color='#8be9fd', edgecolor='#444', alpha=0.8)
plt.axhline(0, color='k', linestyle='--', linewidth=1)
plt.xlabel('Fitted values')
plt.ylabel('Residuals')
plt.title('Residuals vs Fitted')
plt.tight_layout()
plt.show()
```

::::

## Avaliando o modelo linear {.smaller}

:::: {.columns}

```{python}
# QQ-plot of residuals
sm.qqplot(resid, line='s')
plt.title('QQ-plot of residuals')
plt.tight_layout()
plt.show()
```

::::

## Avaliando o modelo linear {.smaller}

:::: {.columns}

```{python}
# Scale-Location (sqrt standardized residuals) plot
std_resid = resid / np.std(resid, ddof=1)
plt.figure(figsize=(6,4))
sns.scatterplot(x=y_pred, y=np.sqrt(np.abs(std_resid)), color='#8be9fd', edgecolor='#444', alpha=0.8)
plt.xlabel('Fitted values')
plt.ylabel('Sqrt(|Standardized residuals|)')
plt.title('Scale-Location')
plt.tight_layout()
plt.show()
```

::::

## Avaliando o modelo linear

:::: {.columns}

 - Teste de heterocedasticidade (Breusch-Pagan)

 - Espera-se homocedasticidade na distribução de erros

```{python}
X_with_const = sm.add_constant(df_model[['body_mass_g']])
lm_stat, lm_pvalue, f_stat, f_pvalue = het_breuschpagan(resid, X_with_const)
print(f"Breusch-Pagan -> LM stat={lm_stat:.3f}, p-value={lm_pvalue:.4f}; F stat={f_stat:.3f}, p-value={f_pvalue:.4f}")
```

::::

# Uso de Inteligência Artificial

Material com exemplos criados com GitHub Copilot usando modelo(s):

 - `GPT 5.0`

# Referências

 - Géron, A. Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow. Terceira Edição (capítulo 9). 2025.

 - Vieira, S. Introdução à Bioestatística. 2021.

 - [Regression Analysis - Penguins data](https://www.kaggle.com/code/murilozangari/regression-analysis-penguins-data)

 - [](https://rpubs.com/BiniamSA/1108476)